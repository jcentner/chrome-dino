{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a2f52b8-c51f-42a3-8871-4efd37d3aea9",
   "metadata": {},
   "source": [
    "# Chrome Dino re-write 2023\n",
    "\n",
    "Use Pytorch, stable-baselines3, etc. to build a model to play chrome://dino with reinforcement learning.\n",
    "Works best with \"Start Slow\" disabled\n",
    "\n",
    "## dependencies (todo: make these a requirements.txt)\n",
    "- CUDA-enabled Pytorch (Pytorch 2.00; CUDA 1.18)\n",
    "- Stable-Baselines3 (with extras like OpenCV): https://stable-baselines3.readthedocs.io/en/master/\n",
    "- Protobuf (a training dependency) (3.20.*)\n",
    "- pytesseract (interface to Google Tesseract)\n",
    "- Google Tesseract-OCR ((5.3.1.20230401)\n",
    "- Gym (gym v0.21 since this is used by Stable-Baselines3; RL environment library): https://gymnasium.farama.org/\n",
    "- MSS (crossplatform screenshots)\n",
    "- openCV (2)\n",
    "- selenium (chrome test driver) (ChromeDriver 112.0.5615.49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02089c1-d995-4aee-9be7-904bedcb0f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e79f30-c80d-45da-8183-39dc343a2991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# needed to support old version of gym (0.21) used with Stable-Baselines3\n",
    "# gym 0.21 has installation issue; gym moved to Gymnasium; SB3 still does not support Gymnasium \n",
    "!pip install setuptools==66 Cmake git+https://github.com/openai/gym.git@9180d12e1b66e7e2a1a622614f787a6ec147ac40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f422a8-8eb2-492d-9ab1-b276d95bcf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8364f7c-3701-48c3-95cb-0488f281d699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install mss pydirectinput selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c072b6-553b-4120-801a-0e4de60df5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73768984-360c-4107-8122-6024473d995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from mss import mss\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete\n",
    "import pytesseract\n",
    "import pydirectinput\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import WebDriverException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c6147-2f1e-4fbe-b2cd-449b9cac725c",
   "metadata": {},
   "source": [
    "## set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e774aea-382f-47ec-bbec-ccfee874c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base Gym environment for managing state\n",
    "# Env must implement step and reset; optionally, render \n",
    "# https://www.gymlibrary.dev/api/core/\n",
    "class ChromeDinoRL(Env):\n",
    "    \n",
    "    # initialize environment spaces\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # observation parameters\n",
    "        self.capture = mss()\n",
    "        self.game_window = {'top':140, 'left':20, 'width':540, 'height':300}\n",
    "        self.game_over_window = {'top':260, 'left':240, 'width':320, 'height':60}\n",
    "        \n",
    "        self.obs_width = int(self.game_window[\"width\"] / 4)\n",
    "        self.obs_height = int(self.game_window[\"height\"] / 4)\n",
    "        \n",
    "        # set up observations and actions\n",
    "        # multidimensional array as return output from observation (an image)\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1, self.obs_height, self.obs_width), dtype=np.uint8)\n",
    "        # two actions: jump or not\n",
    "        self.action_space = Discrete(2)\n",
    "        \n",
    "    # run one timestep in the environment\n",
    "    def step(self, action):\n",
    "        # 0 -> spacebar, 1 -> noop\n",
    "        action_map = {\n",
    "            0: 'space',\n",
    "            1: 'no_op'\n",
    "        }\n",
    "        \n",
    "        if action == 0:\n",
    "            pydirectinput.press(action_map[action])\n",
    "        \n",
    "        # update state each timestep\n",
    "        game_over = self.game_over()[0]\n",
    "        obs = self.observe_env()\n",
    "        reward = 1 # stay alive\n",
    "        # experiment with different reward mechanisms\n",
    "        \n",
    "        info = {}\n",
    "        \n",
    "        return obs, reward, game_over, info\n",
    "        \n",
    "    # reset to initial state, return initial observation\n",
    "    def reset(self):\n",
    "        time.sleep(1)\n",
    "        pydirectinput.click(x=200, y=200)\n",
    "        pydirectinput.press('space')\n",
    "        return self.observe_env()\n",
    "        \n",
    "    # capture screen and render with cv2\n",
    "    # close everything with \"q\" \n",
    "    def render(self):\n",
    "        cv2.imshow('Chrome Dino', np.array(self.capture.grab(self.game_window)))\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close()\n",
    "    \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    # do an observation\n",
    "    def observe_env(self):        \n",
    "        #obs = self.capture.grab(self.game_window)\n",
    "        obs = np.array(self.capture.grab(self.game_window)).astype(np.uint8)\n",
    "        \n",
    "        # preprocessing -> grayscale, shrink, then reshape for Stable Baselines\n",
    "        gray = cv2.cvtColor(obs, cv2.COLOR_BGR2GRAY)\n",
    "        shrunk = cv2.resize(gray, (self.obs_width, self.obs_height))\n",
    "        channel = np.reshape(shrunk, (1, self.obs_height, self.obs_width))\n",
    "        \n",
    "        return channel\n",
    "        \n",
    "    # identify game over\n",
    "    def game_over(self):\n",
    "        game_over = np.array(self.capture.grab(self.game_over_window)).astype(np.uint8)\n",
    "        check_words = ['GAME', 'OVER']\n",
    "        \n",
    "        # preprocess for tesseract-OCR\n",
    "        \n",
    "        # grayscale, gaussian blur, Otsu's threshold\n",
    "        # reference: https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html#otsus-binarization\n",
    "        gray = cv2.cvtColor(game_over, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "        thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # morphological ops to remove remaining noise and invert image to black on white\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1) # erosion + dilation \n",
    "        invert = 255 - opening\n",
    "        \n",
    "        OCR = pytesseract.image_to_string(game_over)\n",
    "        \n",
    "        words = OCR.split()\n",
    "        \n",
    "        if all(word in words for word in check_words):\n",
    "            return True, OCR, invert, words\n",
    "        else:\n",
    "            return False, OCR, invert, words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9bb3e-970d-421f-91c7-30971b8a0edc",
   "metadata": {},
   "source": [
    "## set up driver\n",
    "\n",
    "automated window setup for consistent environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6119728-cab5-414a-b8d2-10b899af13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up webdriver for selenium on chrome\n",
    "# requires chromedriver present in path specified\n",
    "class ChromeDinoDriver():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.chrome_driver = None\n",
    "        self.chrome_path = r\"chromedriver\\chromedriver.exe\" \n",
    "        self.startpage = \"chrome://dino/\"\n",
    "        self.chrome_options = Options()\n",
    "        self.chrome_options.add_argument(\"--window-size=640,480\")\n",
    "        \n",
    "    # set up and run driver\n",
    "    # options \n",
    "    def run(self):\n",
    "        #self.chrome_driver = webdriver.Chrome(executable_path=self.chrome_path, options=self.chrome_options)\n",
    "        self.chrome_driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=self.chrome_options)\n",
    "        self.chrome_driver.set_window_position(0, 0, windowHandle='current')\n",
    "        try:\n",
    "            self.chrome_driver.get(\"chrome://dino\")\n",
    "        except WebDriverException:\n",
    "            pass # ignore selenium complaining about offline\n",
    "\n",
    "    def end(self): # close driver\n",
    "        # duplicates are automatically closed by new selenium service\n",
    "        self.chrome_driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2852c-5473-413a-82b1-17acc0111918",
   "metadata": {},
   "source": [
    "### misc testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18acd610-91ac-440e-ab6c-3c256c443c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test environment\n",
    "env = ChromeDinoRL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7aa8c-ecd9-485b-9326-cd17f9a5eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random action; observation space empty\n",
    "print(env.action_space.sample())\n",
    "plt.imshow(env.observation_space.sample()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba83fc-928f-48d3-b2de-0ef11c610c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try an observation\n",
    "obs = env.observe_env()\n",
    "plt.imshow(cv2.cvtColor(obs[0], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f8804-33b1-474e-98e5-5ffb75fa0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test driver\n",
    "driver = ChromeDinoDriver()\n",
    "driver.run()\n",
    "time.sleep(2)\n",
    "driver.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6118a74-972b-40b3-a727-10334f2a27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start driver and try an observation\n",
    "driver = ChromeDinoDriver()\n",
    "driver.run()\n",
    "plt.imshow(cv2.cvtColor(env.observe_env()[0], cv2.COLOR_BGR2RGB))\n",
    "driver.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e18b6c-8ab4-4cdc-9429-9f2a0bc94320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start driver for testing\n",
    "driver = ChromeDinoDriver()\n",
    "driver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b11ad1-ea88-4384-b5bf-991beef94eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render() # close with env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d6027-6fda-4363-b459-05cb483b0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112bdbf-d39c-40c8-90a1-038234ea7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26aefb5-b60f-4a9c-8c8e-8c2fc3cc06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(env.observe_env()[0], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b754f-5b55-4d6c-a9d7-050fbf1308bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "go = env.game_over()\n",
    "print(\"Game Over? : \" + str(go[0]))\n",
    "print(go[1])\n",
    "print(go[3])\n",
    "plt.imshow(cv2.cvtColor(go[2], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63b16f-a887-4570-baa4-e54e3ec83345",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a76c43-4cf2-4436-8958-fd9a9b70b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test run\n",
    "\n",
    "env = ChromeDinoRL()\n",
    "driver = ChromeDinoDriver()\n",
    "driver.run()\n",
    "\n",
    "for ep in range(4):\n",
    "    obs = env.reset()\n",
    "    game_over = False \n",
    "    score = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        obs, reward, game_over, info = env.step(env.action_space.sample())\n",
    "        score += reward\n",
    "    \n",
    "    print('Score for ep {} = {}.'.format(ep, score))\n",
    "    \n",
    "driver.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba51ccf5-21fe-4c0f-aca6-127bab0bf229",
   "metadata": {
    "tags": []
   },
   "source": [
    "## train model\n",
    "\n",
    "Train the DQN and save it using a Stable-Baselines3 callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c36edc-5817-4ba1-95b5-85ab068220b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training imports\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f802d15e-a1bd-43ed-84a5-df159bcbdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stable baselines callback for saving model and logs during training\n",
    "    \n",
    "CHECKPOINT_DIR = './train/'\n",
    "MODELS_DIR = './models/'\n",
    "LOG_DIR = './logs/'\n",
    "\n",
    "class TrainAndLogCallback(BaseCallback):\n",
    "    \n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLogCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq # number of steps between checkpoints\n",
    "        self.save_path = save_path\n",
    "        self.best_mean_reward = -np.inf\n",
    "        self.log_dir = LOG_DIR\n",
    "        \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "            \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            # save model every check_freq steps\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "            # get training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "            if len(x) > 0:\n",
    "                # show mean training reward over the last check_freq episodes\n",
    "                mean_reward = np.mean(y[(-1*self.check_freq):])\n",
    "                if self.verbose > 0:\n",
    "                    print(\"Num timesteps: {}\".format(self.num_timesteps))\n",
    "                    print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(self.best_mean_reward, mean_reward))\n",
    "            if mean_reward > self.best_mean_reward:\n",
    "                self.best_mean_reward = mean_reward\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c95d6-4baf-4c6c-a724-3a92888fae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLogCallback(check_freq=360, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8887e88-804f-4553-9df1-087d04e5c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DQN\n",
    "# reference: https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html\n",
    "\n",
    "env = ChromeDinoRL()\n",
    "env = Monitor(env, LOG_DIR) # monitor progress using tensorboard logs\n",
    "\n",
    "# check environment - no output means no issues\n",
    "#env_checker.check_env(env)\n",
    "\n",
    "model = DQN(\n",
    "    'CnnPolicy', # passing image observation\n",
    "    env, # registered in Gym \n",
    "    tensorboard_log=LOG_DIR,\n",
    "    verbose=1,\n",
    "    buffer_size=600000, # size of replay buffer; 600k = 12GB-ish RAM\n",
    "    learning_starts=100) # how many steps to collect transitions for before learning starts (100 maybe?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70132370-d27b-482d-a264-c642a1881c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train DQN\n",
    "# higher timesteps = longer training, think TF epochs\n",
    "\n",
    "driver = ChromeDinoDriver()\n",
    "driver.run()\n",
    "time.sleep(1)\n",
    "\n",
    "timesteps = 36000\n",
    "model.learn(total_timesteps=timesteps, callback=callback) #100k decent model\n",
    "\n",
    "time.sleep(1)\n",
    "driver.end()\n",
    "\n",
    "plot_results([log_dir], timesteps, results_plotter.X_TIMESTEPS, \"Chrome Dino\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19843e88-8610-4bc4-8345-0a8a75ba2416",
   "metadata": {},
   "source": [
    "## continual learning\n",
    "\n",
    "Load weights for a pre-trained model and continue training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6648e7-d682-4650-bbc6-f65aa901e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick up where left off and continue training\n",
    "# reference: https://stable-baselines.readthedocs.io/en/master/guide/examples.html#continual-learning\n",
    "# reference: https://github.com/hill-a/stable-baselines/issues/599\n",
    "\n",
    "env = ChromeDinoRL()\n",
    "env = Monitor(env, LOG_DIR) # monitor progress using tensorboard logs\n",
    "\n",
    "# check environment - no output means no issues\n",
    "#env_checker.check_env(env)\n",
    "\n",
    "model_name = 'best_model_'\n",
    "log_name = ''\n",
    "model = DQN.load(os.path.join(CHECKPOINT_DIR, model_name), tensorboard_log=log_name)\n",
    "model.set_env(env)\n",
    "\n",
    "driver = ChromeDinoDriver()\n",
    "driver.run()\n",
    "time.sleep(1)\n",
    "\n",
    "timesteps = 36000\n",
    "model.learn(total_timesteps=timesteps, callback=callback)\n",
    "\n",
    "time.sleep(1)\n",
    "driver.end()\n",
    "\n",
    "plot_results([log_dir], timesteps, results_plotter.X_TIMESTEPS, \"Chrome Dino\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb21966-3abf-4ee4-a180-e62171866725",
   "metadata": {},
   "source": [
    "## use model\n",
    "\n",
    "Load weights for a pre-trained model and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369dbae-fdc8-4f0e-9b8b-ee4e0c9757fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "model_name = 'best_model_'\n",
    "model = DQN.load(os.path.join(MODELS_DIR, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15573a-e6ee-4366-86f1-d86ec7aef3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model in driver and see how it does\n",
    "env = ChromeDinoRL()\n",
    "driver = ChromeDinoDriver()\n",
    "driver.run()\n",
    "time.sleep(1)\n",
    "\n",
    "for ep in range(1):\n",
    "    obs = env.reset()\n",
    "    game_over = False \n",
    "    score = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, game_over, info = env.step(int(action))\n",
    "        score += reward\n",
    "    \n",
    "    print('Score for ep {} = {}.'.format(ep, score))\n",
    "    time.sleep(3)\n",
    "    \n",
    "driver.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
